{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating LLM Perspectives from GlobalOpinionQA Dataset\n",
    "The paper [Towards Measuring the Representation of Subjective Global Opinions in Language Models](https://huggingface.co/datasets/Anthropic/llm_global_opinions) introduces the GlobalOpinionQA dataset containing survey questions about global issues and opinions from participants from many countries.\n",
    "\n",
    "To convert the ordinal multiple choice answers into free text answers, we will use LLMs to generate perspectives based on the aggregate statistics in the dataset and save as a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import pandas as pd, numpy as np, os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "TEMP_PATH = os.getenv('TEMP_PATH')\n",
    "DATA_PATH = os.getenv('DATA_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Anthropic/llm_global_opinions\")\n",
    "df = ds['train'].to_pandas()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Convert string representation of defaultdict to regular dict\n",
    "def convert_defaultdict_str(s):\n",
    "    try:\n",
    "        # Extract the dictionary part from the defaultdict string\n",
    "        dict_str = s.split('defaultdict(<class \\'list\\'>, ')[1][:-1]\n",
    "        # Parse the dictionary string\n",
    "        return ast.literal_eval(dict_str)\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "df['selections'] = df['selections'].apply(convert_defaultdict_str)\n",
    "df['options'] = df['options'].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Generation of LLM Perspectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountryPerspective(BaseModel):\n",
    "    option: str\n",
    "    perspective: str\n",
    "\n",
    "class CountryPerspectiveList(BaseModel):\n",
    "    perspectives: list[CountryPerspective]\n",
    "\n",
    "\n",
    "def generate_country_perspectives(question: str, options: list[str], country: str, max_retries: int = 1):\n",
    "    \"\"\"\n",
    "    Generate perspectives for the given country explaining their choice of options.\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"You are a helpful assistant that generates multiple perspectives of answers to a question. You will be given a question, a country, and a list of answer options, and you will generate a list of possible answer perspectives from the perspective of people from that country. Make sure you cover all possible perspectives but do not repeat yourself.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"Question: {question}\n",
    "    Country: {country}\n",
    "    Options: {', '.join(options)}\n",
    "    Now, step by step, outline each broad answer perspective to this question from the perspective of a person from the country and each of the answer options.\n",
    "    \"\"\"\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            chat_response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=1,\n",
    "                response_format={\n",
    "                    'type': 'json_schema',\n",
    "                    'json_schema': {\n",
    "                        \"name\": \"CountryPerspectiveList\",\n",
    "                        \"schema\": CountryPerspectiveList.model_json_schema()\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "\n",
    "            result_object = json.loads(chat_response.choices[0].message.content)\n",
    "            # Validate the response using Pydantic\n",
    "            validated_response = CountryPerspectiveList.model_validate(result_object)\n",
    "            return [p.perspective for p in validated_response.perspectives]\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            if retries == max_retries:\n",
    "                print(f\"Error for {country} - {question} (after {retries} retries): {str(e)}\")\n",
    "                return [f\"Error generating perspective: {str(e)}\"]\n",
    "            print(f\"Attempt {retries} failed, retrying...\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perspectives(df, total_length=None):\n",
    "    if total_length is None or total_length > len(df):\n",
    "        total_length = len(df)\n",
    "    \n",
    "    # Create a new dataframe with just the rows we need\n",
    "    working_df = df.head(total_length).copy()\n",
    "    \n",
    "    perspectives = []\n",
    "    for _, row in working_df.iterrows():\n",
    "        countries = list(row['selections'].keys())\n",
    "        options = [str(x) for x in row['options']],\n",
    "        country_perspectives = {}\n",
    "        for country in countries:\n",
    "            country_perspectives[country] = generate_country_perspectives(\n",
    "                row['question'],\n",
    "                options, \n",
    "                country\n",
    "            )\n",
    "        perspectives.append(country_perspectives)\n",
    "    \n",
    "    # Only modify the rows we processed\n",
    "    working_df['country_perspectives'] = perspectives\n",
    "    return working_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is soooOOOooo slooOOoowWWww. Lets get this parallelized!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "# Parallel processing with single progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Split the dataframe into chunks\n",
    "chunk_size = 15 \n",
    "total_rows = 150\n",
    "chunks = np.array_split(df.head(total_rows), 10)\n",
    "\n",
    "# Function to process each chunk\n",
    "def process_chunk(chunk_df):\n",
    "    return generate_perspectives(chunk_df, total_length=len(chunk_df))\n",
    "\n",
    "\n",
    "# Process chunks in parallel using ThreadPoolExecutor with a single progress bar\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    perspectives_chunks = list(tqdm(\n",
    "        executor.map(process_chunk, chunks),\n",
    "        total=len(chunks),\n",
    "        desc=\"Processing chunks\"\n",
    "    ))\n",
    "\n",
    "# Combine results\n",
    "df_with_perspectives = pd.concat(perspectives_chunks, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 5 questions and display their details\n",
    "sample_df = df_with_perspectives.head()\n",
    "\n",
    "# Display the results in a readable format by printing the question and each of the country perspectives\n",
    "for index, row in sample_df.iterrows():\n",
    "    print(row['question'])\n",
    "    for country, perspectives in row['country_perspectives'].items():\n",
    "        print(f\"\\t{country}: {'; '.join(perspectives)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep things separate and clean, we're going to save these to a different file.\n",
    "df_with_perspectives.to_csv(DATA_PATH+f'GlobalOpinionQA_with_LLM_generated_perspectives_{total_rows}.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oeenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
